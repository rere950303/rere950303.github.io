---
title: "[Spring][Batch] Spring Batch"
last\_modified\_at: 2022-01-03T 3:38 +09:00
header:
  overlay\_color: "#333"
Batch_1:
    - url: /assets/images/post/Spring/Batch/1.png
      image_path: /assets/images/post/Spring/Batch/1.png
Batch_2:
    - url: /assets/images/post/Spring/Batch/2.png
      image_path: /assets/images/post/Spring/Batch/2.png
Batch_3:
    - url: /assets/images/post/Spring/Batch/3.png
      image_path: /assets/images/post/Spring/Batch/3.png
Batch_4:
    - url: /assets/images/post/Spring/Batch/4.png
      image_path: /assets/images/post/Spring/Batch/4.png
Batch_5:
    - url: /assets/images/post/Spring/Batch/5.png
      image_path: /assets/images/post/Spring/Batch/5.png
Batch_6:
    - url: /assets/images/post/Spring/Batch/6.png
      image_path: /assets/images/post/Spring/Batch/6.png
Batch_7:
    - url: /assets/images/post/Spring/Batch/7.png
      image_path: /assets/images/post/Spring/Batch/7.png
Batch_8:
    - url: /assets/images/post/Spring/Batch/8.png
      image_path: /assets/images/post/Spring/Batch/8.png
Batch_9:
    - url: /assets/images/post/Spring/Batch/9.png
      image_path: /assets/images/post/Spring/Batch/9.png
Batch_10:
    - url: /assets/images/post/Spring/Batch/10.png
      image_path: /assets/images/post/Spring/Batch/10.png
Batch_11:
    - url: /assets/images/post/Spring/Batch/11.png
      image_path: /assets/images/post/Spring/Batch/11.png
    - url: /assets/images/post/Spring/Batch/12.png
      image_path: /assets/images/post/Spring/Batch/12.png
Batch_13:
    - url: /assets/images/post/Spring/Batch/13.png
      image_path: /assets/images/post/Spring/Batch/13.png
Batch_14:
    - url: /assets/images/post/Spring/Batch/14.png
      image_path: /assets/images/post/Spring/Batch/14.png
    - url: /assets/images/post/Spring/Batch/15.png
      image_path: /assets/images/post/Spring/Batch/15.png
Batch_16:
    - url: /assets/images/post/Spring/Batch/16.png
      image_path: /assets/images/post/Spring/Batch/16.png
Batch_17:
    - url: /assets/images/post/Spring/Batch/17.png
      image_path: /assets/images/post/Spring/Batch/17.png
Batch_18:
    - url: /assets/images/post/Spring/Batch/18.png
      image_path: /assets/images/post/Spring/Batch/18.png
Batch_19:
    - url: /assets/images/post/Spring/Batch/19.png
      image_path: /assets/images/post/Spring/Batch/19.png
Batch_20:
    - url: /assets/images/post/Spring/Batch/20.png
      image_path: /assets/images/post/Spring/Batch/20.png
Batch_21:
    - url: /assets/images/post/Spring/Batch/21.png
      image_path: /assets/images/post/Spring/Batch/21.png
Batch_22:
    - url: /assets/images/post/Spring/Batch/22.png
      image_path: /assets/images/post/Spring/Batch/22.png
Batch_23:
    - url: /assets/images/post/Spring/Batch/23.png
      image_path: /assets/images/post/Spring/Batch/23.png
Batch_24:
    - url: /assets/images/post/Spring/Batch/24.png
      image_path: /assets/images/post/Spring/Batch/24.png
Batch_25:
    - url: /assets/images/post/Spring/Batch/25.png
      image_path: /assets/images/post/Spring/Batch/25.png
Batch_26:
    - url: /assets/images/post/Spring/Batch/26.png
      image_path: /assets/images/post/Spring/Batch/26.png
    - url: /assets/images/post/Spring/Batch/27.png
      image_path: /assets/images/post/Spring/Batch/27.png
    - url: /assets/images/post/Spring/Batch/28.png
      image_path: /assets/images/post/Spring/Batch/28.png
Batch_29:
    - url: /assets/images/post/Spring/Batch/29.png
      image_path: /assets/images/post/Spring/Batch/29.png
Batch_30:
    - url: /assets/images/post/Spring/Batch/30.png
      image_path: /assets/images/post/Spring/Batch/301.png
Batch_31:
    - url: /assets/images/post/Spring/Batch/31.png
      image_path: /assets/images/post/Spring/Batch/31.png
Batch_32:
    - url: /assets/images/post/Spring/Batch/32.png
      image_path: /assets/images/post/Spring/Batch/32.png
Batch_33:
    - url: /assets/images/post/Spring/Batch/33.png
      image_path: /assets/images/post/Spring/Batch/33.png
categories:
  - Spring/Batch
tags:
  - Batch
  - Spring
---
## 들어가며
해당 게시글은 인프런 정수원 강사님의 [스프링 배치 - Spring Boot 기반으로 개발하는 Spring Batch][1] 강의를 바탕으로 쓰였음을 미리 밝힙니다.

## 스프링 배치 소개
### 개요
- 배치 핵심 패턴
  - Read: 데이터베이스, 파일, 큐에서 다량의 데이터 조회한다.
  - Process: 특정 방법으로 데이터를 가공한다.
  - Write: 데이터를 수정된 양식으로 다시 저장한다.
- 배치 시나리오
  - 배치 프로세스를 주기적으로 커밋
  - 동시 다발적인 Job의 배치처리, 대용량 병렬 처리(멀티쓰레드)
  - 실패 후 수동 또는 스케줄링에 의한 재시작
  - 의존관계가 있는 step 여러 개를 순차적으로 처리
  - 조건적 Flow 구성을 통한 체계적이고 유연한 배치 모델 구성
  - 반복, 재시도, Skip 처리

### 아키텍처
- Application
  - 스프링 배치 프레임워크를 통해 개발자가 만든 모든 배치 Job과 커스텀 코드를 포함
  - 개발자는 업무로직의 구현에만 집중하고 공통적인 기반기술은 프레임웍이 담당하게 한다.
- Batch Core
  - Job을 실행, 모니터링, 관리하는 API로 구성되어 있다.
  - JobLauncher, Job, Step, Flow 등이 속한다.
- Batch Intrastructure
  - Application, Core 모두 공통 Infrastructure 위에서 빌드한다.
  - Job 실행의 흐름과 처리를 위한 틀을 제공함
  - Reader, Processor Writer, Skip, Retry 등이 속한다.

## 스프링 배치 시작
### 스프링 배치 활성화
- `@EnableBatchProcessing`: 총 4개의 설정 클래스를 실행시키며 스프링 배치의 모든 초기화 및 실행 구성이 이루어진다. 스프링 부트 배치의 자동 설정 클래스가 실행됨으로 빈으로 등록된 모든 Job 을 검색해서 초기화와 동시에 Job 을 수행하도록 구성됨
- 스프링 배치 초기화 설정 클래스
  - BatchAutoConfiguration: 스프링 배치가 초기화 될 때 자동으로 실행되는 설정 클래스, Job 을 수행하는 JobLauncherApplicationRunner 빈을 생성
  - SimpleBatchConfiguration: JobBuilderFactory 와 StepBuilderFactory 생성, 스프링 배치의 주요 구성요소 생성 - 프록시 객체로 생성됨
  - BatchConfigurerConfiguration
    - BasicBatchConfigurer: SimpleBatchConfiguration 에서 생성한 프록시 객체의 실제 대상 객체를 생성하는 설정 클래스, 빈으로 의존성 주입 받아서 주요 객체들을 참조해서 사용할 수 있다.
    - JpaBatchConfigurer: JPA 관련 객체를 생성하는 설정 클래스
    - 사용자 정의 BatchConfigurer 인터페이스를 구현하여 사용할 수 있음

### Hello Spring Batch 시작하기
```java
@RequiredArgsConstructor
@Configuration
public class HelloJobConfiguration {

    private final JobBuilderFactory jobBuilderFactory; // Job을 생성하는 빌더 팩토리
    private final StepBuilderFactory stepBuilderFactory; // Step을 생성하는 빌더 팩토리

    @Bean
    public Job helloJob() {
        return jobBuilderFactory.get("helloJob")
                .start(helloStep1())
                .next(helloStep2())
                .build();
    }

    @Bean
    public Step helloStep1() {
        return stepBuilderFactory.get("helloStep1")
                .tasklet(new Tasklet() { // Step 안에서 단일 태스크로 수행되는 로직 구현
                    @Override
                    public RepeatStatus execute(StepContribution contribution, ChunkContext chunkContext) throws Exception {
                        System.out.println("=============================");
                        System.out.println(" >> Hello Spring Step1!!");
                        System.out.println("=============================");
                        return RepeatStatus.FINISHED;
                    }
                }).build();
    }
}
```
- Job 구동 -> Step을 실행 -> Taskelt 실행
- Job: 일, Step: 일의 항목, Taskelt: 작업 내용

### DB 스키마 생성
- 스프링 배치의 실행 및 관리를 위한 목적으로 여러 도메인들(Job, Step, JobParameters..) 의 정보들을 저장, 업데이트, 조회할 수 있는 스키마 제공
- 과거, 현재의 실행에 대한 세세한 정보, 실행에 대한 성공과 실패 여부 등을 일목요연하게 관리함으로서 배치운용에 있어 리스크 발생시 빠른 대처 가능
- DB와 연동할 경우 필수적으로 메타 테이블이 생성 되어야함
- 스키마 생성 설정
  - 수동 생성 – 쿼리 복사 후 직접 실행
  - 자동 생성 - spring.batch.jdbc.initialize-schema 설정
    - ALWAYS: 스크립트 항상 실행, RDBMS 설정이 되어 있을 경우 내장 DB 보다 우선적으로 실행
    - EMBEDDED: 내장 DB일 때만 실행되며 스키마가 자동 생성됨, 기본값
    - NEVER: 스크립트 항상 실행 안함, 내장 DB 일경우 스크립트가 생성이 안되기 때문에 오류 발생, 운영에서 수동으로 스크립트 생성 후 설정하는 것을 권장

{% include gallery id="Batch_1" %}
- Job 관련 테이블
  - BATCH_JOB_INSTANCE: Job이 실행될 때 JobInstance 정보가 저장되며 job_name과 job_key를 하나의 데이터로 저장, 동일한 job_name과 job_key로 중복 저장될 수없다.
  - BATCH_JOB_EXECUTION: job 의 실행정보가 저장되며 Job 생성, 시작, 종료 시간, 실행상태, 메시지 등을 관리
  - BATCH_JOB_EXECUTION_PARAMS: Job과 함께 실행되는 JobParameter 정보를 저장
  - BATCH_JOB_EXECUTION_CONTEXT: Job의 실행동안 여러가지 상태정보, 공유 데이터를 직렬화(Json형식)해서 저장, Step간 서로 공유 가능함
- Step 관련 테이블
  - BATCH_STEP_EXECUTION: Step 의 실행정보가 저장되며 생성, 시작, 종료 시간, 실행상태, 메시지 등을 관리
  - BATCH_STEP_EXECUTION_CONTEXT: Step의 실행동안 여러가지 상태정보, 공유 데이터를 직렬화(Json형식)해서 저장
  - Step 별로 저장되며 Step간 서로 공유할 수 없음

## 스프링 배치 도메인 이해
### Job
- 기본 개념
  - 배치 계층 구조에서 가장 상위에 있는 개념으로서 하나의 배치작업 자체를 의미함
  - Job Configuration 을 통해 생성되는 객체 단위로서 배치작업을 어떻게 구성하고 실행할 것인지 전체적으로 설정하고 명세해 놓은 객체
  - 배치 Job 을 구성하기 위한 최상위 인터페이스이며 스프링 배치가 기본 구현체를 제공한다.
  - 여러 Step 을 포함하고 있는 컨테이너로서 반드시 한개 이상의 Step으로 구성해야 함
- 기본 구현체
  - SimpleJob: 순차적으로 Step 을 실행시키는 Job
  - FlowJob: 특정한 조건과 흐름에 따라 Step 을 구성하여 실행시키는 Job, Flow 객체를 실행시켜서 작업을 진행함

{% include gallery id="Batch_2" %}

### JobInstance
- 기본 개념 
  - Job이 실행될 때 생성되는 Job의 논리적 실행 단위 객체로서 고유하게 식별 가능한 작업 실행을 나타냄
  - Job의 설정과 구성은 동일하지만 Job이 실행되는 시점에 처리하는 내용은 다르기 때문에 Job의 실행을 구분해야 함
  - 처음 시작하는 Job + JobParameter 일 경우 새로운 JobInstance 생성
  - 이전과 동일한 Job + JobParameter 으로 실행 할 경우 이미 존재하는 JobInstance 리턴 -> 내부적으로 JobName + jobKey (jobParametes 의 해시값) 를 가지고 JobInstance 객체를 얻음
- BATCH_JOB_INSTANCE 테이블과 매핑
  - JOB_NAME (Job) 과 JOB_KEY (JobParameter 해시값) 가 동일한 데이터는 중복해서 저장할 수 없음

{% include gallery id="Batch_3" %}

### JobParameter
- 기본 개념
  - Job을 실행할 때 함께 포함되어 사용되는 파라미터를 가진 도메인 객체
  - 하나의 Job에 존재할 수 있는 여러개의 JobInstance를 구분하기 위한 용도
- 생성 및 바인딩
  - 어플리케이션 실행 시 주입: `Java -jar LogBatch.jar requestDate=20210101`
  - 코드로 생성: JobParameterBuilder
  - SpEL 이용: `@Value(“#{jobParameter[requestDate]}”)`, `@JobScope`, `@StepScope` 선언 필수
- BATCH_JOB_EXECUTION_PARAM 테이블과 매핑
  - JOB_EXECUTION 과 1:M 의 관계

### JobExecution
- 기본 개념
  - JobIstance 에 대한 한번의 시도를 의미하는 객체로서 Job 실행 중에 발생한 정보들을 저장하고 있는 객체
  - JobExecution은 'FAILED' 또는 'COMPLETED‘ 등의 Job의 실행 결과 상태를 가지고 있음
  - JobExecution 의 실행 상태 결과가 'COMPLETED’ 면 JobInstance 실행이 완료된 것으로 간주해서 재실행이 불가함
  - JobExecution 의 실행 상태 결과가 'FAILED’ 면 JobInstance 실행이 완료되지 않은 것으로 간주해서 재실행이 가능함(JobParameter 가 동일한 값으로 Job 을 실행할지라도 JobInstance 를 계속 실행할 수 있음)
- BATCH_JOB_EXECUTION 테이블과 매핑
  - JobInstance 와 JobExecution 는 1:M 의 관계로서 JobInstance 에 대한 성공/실패의 내역을 가지고 있음

{% include gallery id="Batch_4" %}

### Step
- 기본 개념
  - Batch job을 구성하는 독립적인 하나의 단계로서 실제 배치 처리를 정의하고 컨트롤하는 데 필요한 모든 정보를 가지고 있는 도메인 객체CFc
  - 단순한 단일 태스크 뿐 아니라 입력과 처리 그리고 출력과 관련된 복잡한 비즈니스 로직을 포함하는 모든 설정들을 담고 있다.
  - 배치작업을 어떻게 구성하고 실행할 것인지 Job 의 세부 작업을 Task 기반으로 설정하고 명세해 놓은 객체
  - 모든 Job은 하나 이상의 step으로 구성됨
- 기본 구현체
  - TaskletStep: 가장 기본이 되는 클래스로서 Tasklet 타입의 구현체들을 제어한다
  - PartitionStep: 멀티 스레드 방식으로 Step 을 여러 개로 분리해서 실행한다
  - JobStep: Step 내에서 Job 을 실행하도록 한다
  - FlowStep: Step 내에서 Flow 를 실행하도록 한다.

### StepExecution
- 기본 개념
  - Step 에 대한 한번의 시도를 의미하는 객체로서 Step 실행 중에 발생한 정보들을 저장하고 있는 객체
  - Step 이 매번 시도될 때마다 생성되며 각 Step 별로 생성된다.
  - Job이 재시작 하더라도 이미 성공적으로 완료된 Step은 재실행 되지않고 실패한 Step만 실행된다.
  - 이전 단계 Step이 실패해서 현재 Step을 실행하지 않았다면 StepExecution을 생성하지 않는다. Step이 실제로 시작됐을 때만 StepExecution을 생성한다.
- BATCH_STEP_EXECUTION 테이블과 매핑
  - JobExecution 와 StepExecution 는 1:M 의 관계

### StepContribution
- 청크 프로세스의 변경 사항을 버퍼링 한 후 StepExecution 상태를 업데이트하는 도메인 객체
- 청크 커밋 직전에 StepExecution 의 apply 메서드를 호출하여 상태를 업데이트 함

{% include gallery id="Batch_5" %}

### ExecutionContext
- 프레임워크에서 유지 및 관리하는 키/값으로 된 컬렉션으로 StepExecution 또는 JobExecution 객체의 상태(state)를 저장하는 공유 객체
- 공유 범위
  - Step 범위 – 각 Step 의 StepExecution 에 저장되며 Step 간 서로 공유 안됨
  - Job 범위 – 각 Job의 JobExecution 에 저장되며 Job 간 서로 공유 안되며 해당 Job의 Step 간 서로 공유됨

### JobRepository
- 배치 작업 중의 정보를 저장하는 저장소 역할
- Job이 언제 수행되었고, 언제 끝났으며, 몇 번이 실행되었고 실행에 대한 결과 등의 배치 작업의 수행과 관련된 모든 meta data 를 저장함(JobLauncher, Job, Step 구현체 내부에서 CRUD 기능을 처리함)

{% include gallery id="Batch_6" %}
- JobRepository 설정
  - `@EnableBatchProcessing` 어노테이션만 선언하면 JobRepository 가 자동으로 빈으로 생성됨
  - BatchConfigurer 인터페이스를 구현하거나 BasicBatchConfigurer 를 상속해서 JobRepository 설정을 커스터마이징 할 수 있다.

### JobLauncher
- 배치 Job 을 실행시키는 역할을 한다.
- Job과 Job Parameters를 인자로 받으며 요청된 배치 작업을 수행한 후 최종 client 에게 JobExecution을 반환함
- 스프링 부트 배치가 구동이 되면 JobLauncher 빈이 자동 생성 된다.(`JobLanucher.run(Job, JobParameters)`)
- 스프링 부트 배치에서는 JobLauncherApplicationRunner 가 자동적으로 JobLauncher 을 실행시킨다.
- 동기적 실행
  - taskExecutor 를 SyncTaskExecutor 로 설정할 경우 (기본값은 SyncTaskExecutor)
  - JobExecution 을 획득하고 배치 처리를 최종 완료한 이후 Client 에게 JobExecution 을 반환
- 비 동기적 실행
  - taskExecutor 가 SimpleAsyncTaskExecutor 로 설정할 경우
  - JobExecution 을 획득한 후 Client 에게 바로 JobExecution 을 반환하고 배치처리를 완료한다.
  - HTTP 요청에 의한 배치 처리에 적합함 – 배치처리 시간이 길 경우 응답이 늦어지지 않도록 함

## 스프링 배치 실행 - Job
### 배치 초기화 설정
- JobLauncherApplicationRunner
  - Spring Batch 작업을 시작하는 ApplicationRunner 로서 BatchAutoConfiguration 에서 생성됨
  - 스프링 부트에서 제공하는 ApplicationRunner 의 구현체로 어플리케이션이 정상적으로 구동되자 마다 실행됨
  - 기본적으로 빈으로 등록된 모든 job 을 실행시킨다.
- BatchProperties
  - Spring Batch 의 환경 설정 클래스
  - Job 이름, 스키마 초기화 설정, 테이블 Prefix 등의 값을 설정할 수 있다.
- Job 실행 옵션
  - 지정한 Batch Job만 실행하도록 할 수 있음(`spring.batch.job.names: ${job.name:NONE}`)
  - 어플리케이션 실행시 Program arguments 로 job 이름 입력한다.(`--job.name=helloJob`, `--job.name=helloJob,simpleJob`)

```yaml
spring:
  batch:
    jdbc:
      initialize-schema: always
    job:
      enabled: false
      names: ${job.name:NONE}
```

### JobBuilderFactory / JobBuilder
- 스프링 배치는 Job과 Step을 쉽게 생성 및 설정할 수 있도록 util 성격의 빌더 클래스들을 제공함
- JobBuilderFactory
  - JobBuilder 를 생성하는 팩토리 클래스로서 get(String name) 메서드 제공
- JobBuilder
  - Job을 구성하는 설정 조건에 따라 두 개의 하위 빌더 클래스를 생성하고 실제 Job 생성을 위임한다.
  - SimpleJobBuilder: SimpleJob 을 생성하는 Builder 클래스
  - FlowJobBuilder: FlowJob 을 생성하는 Builder 클래스, 내부적으로 FlowBuilder 를 반환함으로써 Flow 실행과 관련된 여러 설정 API 를 제공한다.

{% include gallery id="Batch_7" %}

### SimpleJob
- SimpleJob 은 Step 을 실행시키는 Job 구현체로서 SimpleJobBuilder 에 의해 생성된다.
- 여러 단계의 Step 으로 구성할 수 있으며 Step 을 순차적으로 실행시킨다.
- 맨 마지막에 실행한 Step 의 BatchStatus 가 Job 의 최종 BatchStatus 가 된다.

```java
public Job batchJob() {
    return jobBuilderFactory.get("batchJob") // JobBuilder 를 생성하는 팩토리, Job 의 이름을 매개변수로 받음
            .start(Step) // 처음 실행 할 Step 설정, 최초 한번 설정, 이 메서드를 실행하면 SimpleJobBuilder 반환
            .next(Step) // 다음에 실행 할 Step 설정, 횟수는 제한이 없으며 모든 next() 의 Step 이 종료가 되면 Job 이 종료된다
            .incrementer(JobParametersIncrementer) // JobParameter 의 값을 자동을 증가해 주는 JobParametersIncrementer 설정
            .preventRestart() // Job 의 재시작 가능 여부 설정, 기본값은 true
            .validator(JobParameterValidator) // JobParameter 를 실행하기 전에 올바른 구성이 되었는지 검증하는 JobParametersValidator 설정
            .listener(JobExecutionListener) // Job 라이프 사이클의 특정 시점에 콜백 제공받도록 JobExecutionListener 설정
            .build(); // SimpleJob 생성
}
```

### SimpleJob - validator()
- Job 실행에 꼭 필요한 파라미터를 검증하는 용도
- DefaultJobParametersValidator 구현체를 지원하며, 좀 더 복잡한 제약 조건이 있다면 인터페이스를 직접 구현할 수도 있음
- requiredKeys, optionalKeys
- JobParametersInvalidException, Validation Success

### SimpleJob - preventRestart()
- Job 의 재시작 여부를 설정
- 기본 값은 true 이며 false 로 설정 시 “ 이 Job은 재시작을 지원하지 않는다 ” 라는 의미
- Job 이 실패해도 재 시작이 안되며 Job을 재시작하려고 하면 JobRestartException이 발생
- Job 의 실행이 처음이 아닌 경우는 Job 의 성공/실패와 상관없이 오직 preventRestart 설정 값에 따라서 실행 여부를 판단한다.

{% include gallery id="Batch_8" %}
### SimpleJob - incrementer()
- JobParameters 에서 필요한 값을 증가시켜 다음에 사용될 JobParameters 오브젝트를 리턴
- **기존의** JobParameter 변경없이 Job 을 여러 번 시작하고자 할때
- RunIdIncrementer 구현체를 지원하며 인터페이스를 직접 구현할 수 있음
  
### SimpleJob 아키텍처
{% include gallery id="Batch_9" %}

## 스프링 배치 실행 - Step
### StepBuilderFactory
- StepBuilderFactory
  - StepBuilder 를 생성하는 팩토리 클래스로서 get(String name) 메서드 제공
- StepBuilder: Step을 구성하는 설정 조건에 따라 다섯 개의 하위 빌더 클래스를 생성하고 실제 Step 생성을 위임한다.
  - TaskletStepBuilder: TaskletStep 을 생성하는 기본 빌더 클래스
  - SimpleStepBuilder: TaskletStep 을 생성하며 내부적으로 청크기반의 작업을 처리하는 ChunkOrientedTasklet 클래스를 생성한다.
  - PartitionStepBuilder: PartitionStep 을 생성하며 멀티 스레드 방식으로 Job 을 실행한다.
  - JobStepBuilder: JobStep 을 생성하여 Step 안에서 Job 을 실행한다.
  - FlowStepBuilder: FlowStep 을 생성하여 Step 안에서 Flow 를 실행한다.

### TaskletStep - 개념 및 API 소개
- 스프링 배치에서 제공하는 Step 의 구현체로서 Tasklet 을 실행시키는 도메인 객체
- RepeatTemplate 를 사용해서 Tasklet 의 구문을 트랜잭션 경계 내에서 반복해서 실행함
- Task 기반과 Chunk 기반으로 나누어서 Tasklet 을 실행함
- Task vs Chunk 기반 비교
  - Task 기반: 단일 작업 기반으로 처리되는 것이 더 효율적인 경우, 주로 Tasklet 구현체를 만들어 사용, 대량 처리를 하는 경우 chunk 기반에 비해 더 복잡한 구현 필요
  - chunk 기반: 하나의 큰 덩어리를 n개씩 나눠서 실행한다는 의미로 대량 처리를 하는 경우 효과적으로 설계 됨. ItemReader, ItemProcessor, ItemWriter 를 사용하며 청크 기반 전용 Tasklet 인 ChunkOrientedTasklet 구현체가 제공된다.

```java
public Step batchStep() {
    return stepBuilderFactory.get("batchStep") // StepBuilder 를 생성하는 팩토리, Step 의 이름을 매개변수로 받음
            .tasklet(Tasklet) // Tasklet 클래스 설정, 이 메서드를 실행하면 TaskletStepBuilder 반환
            .startLimit(10) // Step의 실행 횟수를 설정, 설정한 만큼 실행되고 초과시 오류 발생, 기본값음 INTEGER.MAX_VALUE
            .allowStartIfComplete(true) // Step의 성공, 실패와 상관없이 항상 Step 을 실행하기 위한 설정
            .listener(StepExecutionListener) // Step 라이프 사이클의 특정 시점에 콜백 제공받도록 StepExecutionListener 설정
            .build(); // TaskletStep 을 생성
}
```

### TaskletStep - tasklet()
- Step 내에서 구성되고 실행되는 도메인 객체로서 주로 단일 태스크를 수행하기위한 것
- TaskletStep 에 의해 반복적으로 수행되며 반환값에 따라 계속 수행 혹은 종료한다.
  - RepeatStatus.FINISHED - Tasklet 종료, RepeatStatus 을 null 로 반환하면 RepeatStatus.FINISHED로 해석됨
  - RepeatStatus.CONTINUABLE - Tasklet 반복
- Step 에 오직 하나의 Tasklet 설정이 가능하며 두개 이상을 설정 했을 경우 마지막에 설정한 객체가 실행된다.

### TaskletStep - startLimit()
- Step의 실행 횟수를 조정할 수 있다.
- Step 마다 설정할 수 있다.
- 설정 값을 초과해서 다시 실행하려고 하면 StartLimitExceededException이 발생
- start-limit의 디폴트 값은 Integer.MAX_VALUE

### TaskletStep - allowStartIfComplete()
- 재시작 가능한 job 에서 Step 의 이전 성공 여부와 상관없이 항상 step 을 실행하기 위한 설정
- 기본적으로 COMPLETED 상태를 가진 Step 은 Job 재시작 시 실행하지 않고 스킵한다.

### TaskletStep 아키텍처
{% include gallery id="Batch_10" %}

### JobStep
- Job 에 속하는 Step 중 외부의 Job 을 포함하고 있는 Step
- 외부의 Job 이 실패하면 해당 Step 이 실패하므로 결국 최종 기본 Job 도 실패한다.
- 모든 메타데이터는 기본 Job 과 외부 Job 별로 각각 저장된다.

```java
public Step jobStep() {
    return stepBuilderFactory.get("jobStep") // StepBuilder 를 생성하는 팩토리, Step 의 이름을 매개변수로 받음
            .job(Job) // JobStep 내 에서 실행 될 Job 설정, JobStepBuilder 반환
            .launcher(JobLauncher) // Job 을 실행할 JobLauncher설정
            .parametersExtractor(JobParametersExtractor) // Step의 ExecutionContext를 Job이 실행되는 데 필요한 JobParameters로 변환
            .build(); // JobStep 을 생성
}
```

## 스프링 배치 실행 - Flow
### FlowJob - 개념 및 API 소개
- Step 을 순차적으로만 구성하는 것이 아닌 특정한 상태에 따라 흐름을 전환하도록 구성할 수 있으며 FlowJobBuilder 에 의해 생성된다.
- Flow 와 Job 의 흐름을 구성하는데만 관여하고 실제 비즈니스 로직은 Step 에서 이루어진다.
- 내부적으로 SimpleFlow 객체를 포함하고 있으며 Job 실행 시 호출한다.

```java
public Job batchJob() {
    return jobBuilderFactory.get("batchJob") 
            .start(Step) // Flow 시작하는 Step 설정
            .on(String pattern) // Step의 실행 결과로 돌려받는 종료상태 (ExitStatus)를 캐치하여 매칭하는 패턴, TransitionBuilder 반환
            .to(Step) // 다음으로 이동할 Step 지정
            .stop() / fail() / end() / stopAndRestart() //Flow를중지/실패/종료하도록 Flow종료
            .from(Step) // 이전 단계에서 정의한 Step 의 Flow 를 추가적으로 정의함
            .next(Step) // 다음으로 이동할 Step 지정
            .end() // build() 앞에 위치하면 FlowBuilder 를 종료하고 SimpleFlow 객체 생성
            .build() // FlowJob 생성하고 flow 필드에 SimpleFlow 저장
}
```
{% include gallery id="Batch_11" layout = "half"%}

### FlowJob - start() / next()
```java
public Job batchJob() {
    return jobBuilderFactory.get("batchJob")
            .start(Flow) // 처음 실행 할 Flow 설정, JobFlowBuilder 가 반환된다. // 여기에 Step 이 인자로 오게 되면 SimpleJobBuilder 가 반환
            .next(Step or Flow or JobExecutionDecider)
            .on(String pattern)
            .to(Step)
            .stop() / fail() / end() / stopAndRestart()
            .end()
            .build();
}
```

### Transition - 배치상태 유형 (BatchStatus / ExitStatus / FlowExecutionStatus)
- BatchStatus
  - JobExecution 과 StepExecution의 속성으로 Job 과 Step 의 종료 후 최종 결과 상태가 무엇인지 정의
  - SimpleJob: 마지막 Step 의 BatchStatus 값을 Job 의 최종 BatchStatus 값으로 반영, Step 이 실패할 경우 해당 Step 이 마지막 Step 이 된다.
  - FlowJob: Flow 내 Step 의 ExitStatus 값을 FlowExecutionStatus 값으로 저장, 마지막 Flow 의 FlowExecutionStatus 값을 Job 의 최종 BatchStatus 값으로 반영
  - COMPLETED, STARTING, STARTED, STOPPING, STOPPED, FAILED, ABANDONED, UNKNOWN
- ExitStatus
  - JobExecution 과 StepExecution의 속성으로 Job 과 Step 의 실행 후 어떤 상태로 종료되었는지 정의
  - 기본적으로 ExitStatus 는 BatchStatus 와 동일한 값으로 설정된다.
  - SimpleJob: 마지막 Step 의 ExitStatus 값을 Job 의 최종 ExitStatus 값으로 반영
  - FlowJob: Flow 내 Step 의 ExitStatus 값을 FlowExecutionStatus 값으로 저장, 마지막 Flow 의 FlowExecutionStatus 값을 Job 의 최종 ExitStatus 값으로 반영
  - UNKNOWN, EXECUTING, COMPLETED, NOOP, FAILED, STOPPED
- FlowExecutionStatus
  - FlowExecution 의 속성으로 Flow 의 실행 후 최종 결과 상태가 무엇인지 정의
  - Flow 내 Step 이 실행되고 나서 ExitStatus 값을 FlowExecutionStatus 값으로 저장
  - COMPLETED, STOPPED, FAILED, UNKNOWN

### Transition - on() / to() / stop(), fail(), end(), stopAndRestart()
- Transition
  - Flow 내 Step 의 조건부 전환(전이)을 정의함
  - Job 의 API 설정에서 on(String pattern) 메소드를 호출하면 TransitionBuilder 가 반환되어 Transition Flow 를 구성할 수 있음
  - **Step의 종료상태(ExitStatus) 가 어떤 pattern 과도 매칭되지 않으면 스프링 배치에서 예외을 발생하고 Job 은 실패**
  - transition은 구체적인 것부터 그렇지 않은 순서로 적용된다.
- on(String pattern)
  - Step의 실행 결과로 돌려받는 종료상태(ExitStatus)와 매칭하는 패턴 스키마, BatchStatus 와 매칭하는 것이 아님
  - pattern 과 ExitStatus 와 매칭이 되면 다음으로 실행할 Step 을 지정할 수 있다.
  - 특수문자는 두 가지만 허용: “*” : 0개 이상의 문자와 매칭, 모든 ExitStatus 와 매칭된다 / ”?” : 정확히 1개의 문자와 매칭
- to(): 다음으로 실행할 단계를 지정
- from(): 이전 단계에서 정의한 Transition 을 새롭게 추가 정의함
- stop(): FlowExecutionStatus 가 STOPPED 상태로 종료되는 transition, Job 의 BatchStatus 와 ExitStatus 가 STOPPED 으로 종료됨
- fail(): FlowExecutionStatus 가 FAILED 상태로 종료되는 transition, Job 의 BatchStatus 와 ExitStatus 가 FAILED 으로 종료됨
- end(): FlowExecutionStatus 가 COMPLETED 상태로 종료 되는 transition, Job 의 BatchStatus 와 ExitStatus 가 COMPLETED 으로 종료됨, Step 의 ExitStatus 가 FAILED 이더라도 Job 의 BatchStatus 가 COMPLETED 로 종료하도록 가능하며 이 때 Job의 재시작은 불가능함
- stopAndRestart(Step or Flow or JobExecutionDecider): 특정 step에서 작업을 중단하도록 설정하면 중단 이전의 Step 만 COMPLETED 저장되고 이후의 step 은 실행되지 않고 STOPPED 상태로 Job 종료, Job 이 다시 실행됐을 때 실행해야 할 step 을 restart 인자로 넘기면 이전에 COMPLETED 로 저장된 step 은 건너뛰고 중단 이후 step 부터 시작한다.

### 사용자 정의 ExitStatus
- ExitStatus 에 존재하지 않는 exitCode 를 새롭게 정의해서 설정
- StepExecutionListener 의 afterStep() 메서드에서 Custom exitCode 생성 후 새로운 ExitStatus 반환
- Step 실행 후 완료 시점에서 현재 exitCode 를 사용자 정의 exitCode 로 수정할 수 있음

```java
@Bean
public Job batchJob() {
    return this.jobBuilderFactory.get("batchJob")
            .start(step1())
            .on("FAILED")
            .to(step2())
            .on("PASS")
            .stop()
            .end()
            .build();
}

@Bean
public Step step2() {
    return stepBuilderFactory.get("step2")
            .tasklet((contribution, chunkContext) -> {
                System.out.println(">> step2 has executed");
                return RepeatStatus.FINISHED;
            })
            .listener(new PassCheckingListener())
            .build();
}

static class PassCheckingListener extends StepExecutionListenerSupport {

    public ExitStatus afterStep(StepExecution stepExecution) {
        String exitCode = stepExecution.getExitStatus().getExitCode();
        if (!exitCode.equals(ExitStatus.FAILED.getExitCode())) {
            return new ExitStatus("PASS ");
        } else {
            return null;
        }
    }
}
```

### JobExecutionDecider
- ExitStatus 를 조작하거나 StepExecutionListener 를 등록할 필요 없이 Transition 처리를 위한 전용 클래스
- Step 과 Transiton 역할을 명확히 분리해서 설정 할 수 있음
- Step 의 ExitStatus 가 아닌 JobExecutionDecider 의 FlowExecutionStatus 상태값을 새롭게 설정해서 반환함

```java
@Configuration
@RequiredArgsConstructor
public class JobConfiguration {

    private final JobBuilderFactory jobBuilderFactory;
    private final StepBuilderFactory stepBuilderFactory;

    @Bean
    public Job job() {
        return jobBuilderFactory.get("batchJob")
                .incrementer(new RunIdIncrementer())
                .start(step())
                .next(decider())
                .from(decider()).on("ODD").to(oddStep())
                .from(decider()).on("EVEN").to(evenStep())
                .end()
                .build();
    }

    @Bean
    public JobExecutionDecider decider() {
        return new CustomDecider();
    }

    private class CustomDecider implements JobExecutionDecider {

        private int count = 0;

        @Override
        public FlowExecutionStatus decide(JobExecution jobExecution, StepExecution stepExecution) {
            count++;

            if (count % 2 == 0) {
                return new FlowExecutionStatus("EVEN");
            } else {
                return new FlowExecutionStatus("ODD");
            }
        }
    }
}
```

### FlowJob 아키텍처
{% include gallery id="Batch_13" %}

### SimpleFlow - 개념 및 API 소개
- 스프링 배치에서 제공하는 Flow 의 구현체로서 각 요소(Step, Flow, JobExecutionDecider) 들을 담고 있는 State 를 실행시키는 도메인 객체
- FlowBuilder 를 사용해서 생성하며 Transition 과 조합하여 여러 개의 Flow 및 중첩 Flow 를 만들어 Job 을 구성할 수 있다.
- Flow 안에 Step 을 구성하거나 Flow 를 중첩되게 구성할 수 있다.

```java
@Configuration
@RequiredArgsConstructor
public class JobConfiguration {

    private final JobBuilderFactory jobBuilderFactory;
    private final StepBuilderFactory stepBuilderFactory;

    @Bean
    public Job job() {
        return jobBuilderFactory.get("batchJob")
                .start(flow())
                .next(step3())
                .end()
                .build();
    }

    @Bean
    public Flow flow() {
        return new FlowBuilder<Flow>("flow").start(step1())
                .next(step2())
                .end();
    }
}
```
- Flow 안에 Flow와 Step를 포함한 구조

### SimpleFlow 아키텍처
- Step, Flow, Decider 등을 담은 State 생성하여 StateTransition에 담은 후에 이를 토대로 SimpleFlow 속성을 생성한다. `start()`, `resume()`, `nextState()` 메소드를 통해서 조건에 맞는 Transition에 따라 State를 실행시킨다. FlowState 일 경우에는 다시 재귀적 호출이 된다.
- SimpleFlow 는 StateMap 에 저장되어 있는 모든 State 들의 handle 메서드를 호출해서 모든 Step 들이 실행되도록 한다.
- SimpleFlow 는 현재 호출되는 State 가 어떤 타입인지 알지 못하고 관심도 없다. 단지 handle 메소드를 실행하고 상태값을 얻어올 뿐이다.(상태 패턴)

{% include gallery id="Batch_14" layout = "half"%}

### FlowStep
- Step 내에 Flow 를 할당하여 실행시키는 도메인 객체
- flowStep 의 BatchStatus 와 ExitStatus 은 Flow 의 최종 상태값에 따라 결정된다.

```java
@Configuration
@RequiredArgsConstructor
public class JobConfiguration {

    private final JobBuilderFactory jobBuilderFactory;
    private final StepBuilderFactory stepBuilderFactory;

    @Bean
    public Job job() {
        return jobBuilderFactory.get("job")
                .start(flowStep())
                .next(step3())
                .build();
    }

    private Step flowStep() {
        return stepBuilderFactory.get("flowStep")
                .flow(flow())
                .build();
    }

    @Bean
    public Flow flow() {
        return new FlowBuilder<Flow>("flow")
                .start(step1())
                .next(step2())
                .end();
    }
}
```

### @JobScope / @StepScope - 기본개념 및 설정
- 스프링 컨테이너에서 빈이 관리되는 범위
- `@JobScope`, `@StepScope`
  - Job과 Step의 빈 생성과 실행에 관여하는 스코프
  - 프록시 모드를 기본값으로 하는 스코프 - `@Scope(value = "job", proxyMode = ScopedProxyMode.TARGET_CLASS)`
  - 해당 스코프가 선언되면 빈이 생성이 어플리케이션 구동시점이 아닌 빈의 실행시점에 이루어진다. 프록시 모드로 빈이 선언되기 때문에 어플리케이션 구동시점에는 빈의 프록시 객체가 생성되어 실행 시점에 실제 빈을 호출해 준다.
  - @Values를 주입해서 빈의 실행 시점에 값을 참조할 수 있으며 일종의 Lazy Binding 이 가능해 진다.
  - `@Value("#{jobParameters[파라미터명]}")`, `@Value("#{jobExecutionContext[파라미터명]”})`, `@Value("#{stepExecutionContext[파라미터명]”})`
  - 병렬처리 시 각 스레드 마다 생성된 스코프 빈이 할당되기 때문에 스레드에 안전하게 실행이 가능하다.
- `@JobScope`
  - Step 선언문에 정의한다
  - `@Value` : jobParameter, jobExecutionContext 만 사용가능
- `@StepScope`
  - Tasklet이나 ItemReader, ItemWriter, ItemProcessor 선언문에 정의한다.
  - `@Value` : jobParameter, jobExecutionContext, stepExecutionContext 사용가능

### @JobScope / @StepScope 아키텍처
- Proxy 객체 생성: `@JobScope` , `@StepScope` 어노테이션이 붙은 빈 선언은 내부적으로 빈의 Proxy 객체가 생성된다.
- Job 실행 시 Proxy 객체가 실제 빈을 호출해서 해당 메서드를 실행시키는 구조
- JobScope , StepScope: Proxy 객체의 실제 대상이 되는 Bean 을 등록, 해제하는 역할. 실제 빈을 저장하고 있는 JobContext, StepContext 를 가지고 있다.
- JobContext , StepContext: 스프링 컨테이너에서 생성된 빈을 저장하는 컨텍스트 역할, Job 의 실행 시점에서 프록시 객체가 실제 빈을 참조할 때 사용됨

## 스프링 배치 청크 프로세스 이해
### Chunk
- Chunk 란 여러 개의 아이템을 묶은 하나의 덩어리, 블록을 의미
- 한번에 하나씩 아이템을 입력 받아 Chunk 단위의 덩어리로 만든 후 Chunk 단위로 트랜잭션을 처리함, 즉 Chunk 단위의 Commit 과 Rollback 이 이루어짐
- 일반적으로 대용량 데이터를 한번에 처리하는 것이 아닌 청크 단위로 쪼개어서 더 이상 처리할 데이터가 없을 때까지 반복해서 입출력하는데 사용됨
- `Chunk<I>`: ItemReader 로 읽은 하나의 아이템을 Chunk 에서 정한 개수만큼 반복해서 저장하는 타입
- `Chunk<O>`: `Chunk<I>` 를 참조해서 ItemProcessor 에서 적절하게 가공, 필터링한 다음 ItemWriter 에 전달하는 타입

{% include gallery id="Batch_16" %}
```java
@Configuration
@RequiredArgsConstructor
public class JobConfiguration {

    private final JobBuilderFactory jobBuilderFactory;
    private final StepBuilderFactory stepBuilderFactory;

    @Bean
    public Job job() {
        return jobBuilderFactory.get("job")
                .start(step1())
                .next(step2())
                .build();
    }

    @Bean
    public Step step1() {
        return stepBuilderFactory.get("step1")
                .<String, String>chunk(5)
                .reader(new ListItemReader<>(Arrays.asList("item1", "item2", "item3", "item4", "item5")))
                .processor(new ItemProcessor<String, String>() {
                    @Override
                    public String process(String item) throws Exception {
                        Thread.sleep(300);
                        System.out.println("item = " + item);
                        return item + " processed";
                    }
                })
                .writer(new ItemWriter<String>() {
                    @Override
                    public void write(List<? extends String> items) throws Exception {
                        Thread.sleep(300);
                        System.out.println("items = " + items);
                    }
                })
                .build();
    }
}
```

### ChunkOrientedTasklet - 개념 및 API 소개
- ChunkOrientedTasklet 은 스프링 배치에서 제공하는 Tasklet 의 구현체로서 Chunk 지향 프로세싱를 담당하는 도메인 객체
- ItemReader, ItemWriter, ItemProcessor 를 사용해 Chunk 기반의 데이터 입출력 처리를 담당한다.
- TaskletStep 에 의해서 반복적으로 실행되며 ChunkOrientedTasklet 이 실행 될 때마다 매번 새로운 트랜잭션이 생성되어 처리가 이루어진다.
- 내부적으로 ItemReader 를 핸들링 하는 ChunkProvider 와 ItemProcessor, ItemWriter 를 핸들링하는 ChunkProcessor 타입의 구현체를 가진다.

```java
public Step chunkStep() {
    return stepBuilderFactory.get("chunkStep")
            .<I, O>chunk(10) // chunk size 설정, chunk size 는 commit interval 을 의미함, input, output 제네릭타입 설정
            .<I, O>chunk(CompletionPolicy) // Chunk 프로세스를 완료하기 위한 정책 설정 클래스 지정
            .reader(itemReader()) // 소스로 부터 item 을 읽거나 가져오는 ItemReader 구현체 설정
            .writer(itemWriter()) // item 을 목적지에 쓰거나 보내기 위한 ItemWriter 구현체 설정
            .processor(itemProcessor()) // item 을 변형, 가공, 필터링 하기 위한 ItemProcessor 구현체 설정
            .stream(ItemStream()) // 재시작 데이터를 관리하는 콜백에 대한 스트림 등록
            .readerIsTransactionalQueue() // Item 이 JMS, Message Queue Server 와 같은 트랜잭션 외부에서 읽혀지고 캐시할 것인지 여부, 기본값은 false
            .listener(ChunkListener) // Chunk 프로세스가 진행되는 특정 시점에 콜백 제공받도록 ChunkListener 설정
            .build();
}
```

### ChunkOrientedTasklet - ChunkProvider / ChunkProcessor
#### ChunkProvider
- ItemReader 를 사용해서 소스로부터 아이템을 Chunk size 만큼 읽어서 Chunk 단위로 만들어 제공하는 도메인 객체
- Chunk<I> 를 만들고 내부적으로 반복문을 사용해서 ItemReader.read() 를 계속 호출하면서 item 을 Chunk 에 쌓는다.
- 외부로 부터 ChunkProvider 가 호출될 때마다 항상 새로운 Chunk 가 생성된다.
- 반복문 종료 시점: Chunk size 만큼 item 을 읽으면 반복문 종료되고 ChunkProcessor 로 넘어감, ItemReader 가 읽은 item 이 null 일 경우 반복문 종료 및 해당 Step 반복문까지 종료
- 기본 구현체로서 SimpleChunkProvider 와 FaultTolerantChunkProvider 가 있다.

#### ChunkProcessor
- ItemProcessor 를 사용해서 Item 을 변형, 가공, 필터링하고 ItemWriter 를 사용해서 Chunk 데이터를 저장, 출력한다.
- Chunk<O> 를 만들고 앞에서 넘어온 Chunk<I> 의 item 을 한 건씩 처리한 후 Chunk<O> 에 저장한다.
- 외부로 부터 ChunkProcessor 가 호출될 때마다 항상 새로운 Chunk 가 생성된다.
- ItemProcessor 는 설정 시 선택사항으로서 만약 객체가 존재하지 않을 경우 ItemReader 에서 읽은 item 그대로가 Chunk<O> 에 저장된다.
- ItemWriter 처리가 완료되면 Chunk 트랜잭션이 종료하게 되고 Step 반복문에서 ChunkOrientedTasklet 가 새롭게 실행된다.
- ItemWriter 는 Chunk size 만큼 데이터를 Commit 처리 하기 때문에 Chunk size 는 곧 Commit Interval 이 된다.
- 기본 구현체로서 SimpleChunkProcessor 와 FaultTolerantChunkProcessor 가 있다.

### ItemReader / ItemWriter / ItemProcessor 이해
#### ItemReader
- 다양한 입력으로부터 데이터를 읽어서 제공하는 인터페이스
  - 플랫(Flat) 파일 – csv, txt (고정 위치로 정의된 데이터 필드나 특수문자로 구별된 데이터의 행)
  - XML, Json
  - Database
  - JMS, RabbitMQ 와 같은 Messag Queuing 서비스
  - Custom Reader - 구현 시 멀티 스레드 환경에서 스레드에 안전하게 구현할 필요가 있음
- 아이템 하나를 리턴하며 더 이상 아이템이 없는 경우 null 리턴
- 다수의 구현체들이 ItemReader 와 ItemStream 인터페이스를 동시에 구현하고 있음: 파일의 스트림을 열거나 종료, DB 커넥션을 열거나 종료, 입력 장치 초기화 등의 작업
- 기본적으로 스레드에 안전하지 않기 때문에 병렬 처리시 데이터 정합성을 위한 동기화 처리 필요

#### ItemWriter
- Chunk 단위로 데이터를 받아 일괄 출력 작업을 위한 인터페이스
  - 플랫(Flat) 파일 – csv, txt
  - XML, Json
  - Database
  - JMS, RabbitMQ 와 같은 Messag Queuing 서비스
  - Mail Service
  - Custom Writer
- 다수의 구현체들이 ItemWriter 와 ItemStream 을 동시에 구현하고 있음: 파일의 스트림을 열거나 종료, DB 커넥션을 열거나 종료, 출력 장치 초기화 등의 작업

### ItemStream
- ItemReader 와 ItemWriter 처리 과정 중 상태를 저장하고 오류가 발생하면 해당 상태를 참조하여 실패한 곳에서 재 시작 하도록 지원
- 리소스를 열고(open) 닫아야(close) 하며 입출력 장치 초기화 등의 작업을 해야 하는 경우
- ExecutionContext 를 매개변수로 받아서 상태 정보를 업데이트(update) 한다.
- ItemReader 및 ItemWriter 는 ItemStream 을 구현해야 한다.

{% include gallery id="Batch_17" %}

## 스프링 배치 청크 프로세스 활용 - ItemReader
### FlatFileItemReader - 개념 및 API 소개
{% include gallery id="Batch_18" %}

- 2차원 데이터(표)로 표현된 유형의 파일을 처리하는 ItemReader
- Resource 와 LineMapper 두 가지 요소가 필요하다.
- Resource
  - new FileSystemResource(“resource/path/config.xml”)
  - new ClassPathResource(“classpath:path/config.xml)
- LineMapper: 파일의 라인 한줄을 Object 로 변환해서 FlatFileItemReader 로 리턴한다. 단순히 문자열을 받기 때문에 문자열을 토큰화해서 객체로 매핑하는 과정이 필요하다. LineTokenizer 와 FieldSetMapper 를 사용해서 처리한다.
  - FieldSet: 라인을 필드로 구분해서 만든 배열 토큰을 전달하면 토큰 필드를 참조 할수 있도록 한다.
  - LineTokenizer: 입력받은 라인을 FieldSet 으로 변환해서 리턴한다.
  - FieldSetMapper: FieldSet 객체를 받아서 원하는 객체로 매핑해서 리턴한다.

```java
public FlatFileItemReader itemReader() {
    return new FlatFileItemReaderBuilder<T>()
            .name(String name) // 이름 설정, ExecutionContext 내에서 구분하기 위한 key 로 저장
            .resource(Resource) // 읽어야 할 리소스 설정
            .delimited().delimiter("|") // 파일의 구분자를 기준으로 파일을 읽어들이는 설정
            .fixedLength() // 파일의 고정길이를 기준으로 파일을 읽어들이는 설정
            .addColumns(Range..) // 고정길이 범위를 정하는 설정
            .names(String[] fieldNames) // LineTokenizer 로 구분된 라인의 항목을 객체의 필드명과 매핑하도록 설정
            .targetType(Class class)  // 라인의 각 항목과 매핑할 객체 타입 설정
            .addComment(String Comment) // 무시할 라인의 코멘트 기호 설정
            .strict( boolean) // 라인을 읽거나 토큰화 할 때 Parsing 예외가 발생하지 않도록 검증 생략하도록 설정
            .encoding(String encoding) // 파일 인코딩 설정
            .linesToSkip( int linesToSkip) // 파일 상단에 있는 무시할 라인 수 설정
            .saveState( boolean) // 상태정보를 저장할 것인지 설정
            .setLineMapper(LineMapper) // LineMapper 객체 설정
            .setFieldSetMapper(FieldSetMapper) // FieldSetMapper 객체 설정
            .setLineTokenizer(LineTokenizer) // LineTokenizer 객체 설정
            .build();
}
```
- `JobConfig`

```java
@Configuration
@RequiredArgsConstructor
public class JobConfiguration {

    private final JobBuilderFactory jobBuilderFactory;
    private final StepBuilderFactory stepBuilderFactory;

    @Bean
    public Job job() {
        return jobBuilderFactory.get("job")
                .start(step1())
                .next(step2())
                .build();
    }

    @Bean
    public Step step1() {
        return stepBuilderFactory.get("step1")
                .<Customer, Customer>chunk(5)
                .reader(itemReader())
                .writer(new ItemWriter<Customer>() {
                    @Override
                    public void write(List<? extends Customer> items) throws Exception {
                        System.out.println("items = " + items);
                        System.out.println("chunk");
                    }
                })
                .build();
    }

    @Bean
    public ItemReader itemReader() {
        FlatFileItemReader<Customer> itemReader = new FlatFileItemReader<Customer>();
        itemReader.setResource(new ClassPathResource("/customer.csv"));

        DefaultLineMapper<Customer> lineMapper = new DefaultLineMapper<>();
        lineMapper.setTokenizer(new DelimitedLineTokenizer());
        lineMapper.setFieldSetMapper(new CustomerFieldSetMapper());

        itemReader.setLineMapper(lineMapper);
        itemReader.setLinesToSkip(1);

        return itemReader;
    }
}
```
- `DefaultLineMapper`

```java
public class DefaultLineMapper<T> implements LineMapper<T> {

    private LineTokenizer tokenizer;
    private FieldSetMapper<T> fieldSetMapper;

    @Override
    public T mapLine(String line, int lineNumber) throws Exception {
        return fieldSetMapper.mapFieldSet(tokenizer.tokenize(line));
    }

    public void setTokenizer(LineTokenizer tokenizer) {
        this.tokenizer = tokenizer;
    }

    public void setFieldSetMapper(FieldSetMapper<T> fieldSetMapper) {
        this.fieldSetMapper = fieldSetMapper;
    }
}
```
- `CustomerFieldSetMapper`

```java
public class CustomerFieldSetMapper implements FieldSetMapper<Customer> {
    @Override
    public Customer mapFieldSet(FieldSet fieldSet) throws BindException {
        if (fieldSet == null) {
            return null;
        }

        Customer customer = new Customer();
        customer.setName(fieldSet.readString(0));
        customer.setAge(fieldSet.readInt(1));
        customer.setYear(fieldSet.readInt(2));

        return customer;
    }
}
```

### FlatFileItemReader - delimetedlinetokenizer
```java
@Bean
public ItemReader itemReader() {
    return new FlatFileItemReaderBuilder<Customer>()
            .name("flatFile")
            .resource(new ClassPathResource("/customer.csv"))
            .fieldSetMapper(new BeanWrapperFieldSetMapper<>())
            .targetType(Customer.class)
            .linesToSkip(1)
            .delimited().delimiter(",")
            .names("name", "age", "year")
            .build();
}
```

### FlatFileItemReader - fixedlengthtokenizer
```java
@Bean
public ItemReader itemReader() {
    return new FlatFileItemReaderBuilder<Customer>()
            .name("flatFile")
            .resource(new FileSystemResource("/Users/hyungwook/Desktop/Spring/batch/spring-batch/src/main/resources/customer.csv"))
            .fieldSetMapper(new BeanWrapperFieldSetMapper<>())
            .targetType(Customer.class)
            .linesToSkip(1)
            .fixedLength()
            .addColumns(new Range(1,5))
            .addColumns(new Range(6,9))
            .addColumns(new Range(10,11))
            .names("name", "age", "year")
            .build();
}
```

### Exception Handling
- 라인을 읽거나 토큰화 할 때 발생하는 Parsing 예외를 처리할 수 있도록 예외 계층 제공
- 토큰화 검증을 엄격하게 적용하지 않도록 설정하면 Parsing 예외가 발생하지 않도록 할 수 있다.
- FlatFileParseException: ItemReader 에서 파일을 읽어들이는 동안 발생 하는 예외
- FlatFileFormatException: LineTokenizer 에서 토큰화 하는 도중 발생하는 예외, FlatFileParseException 보다 좀 더 구체적인 예외
- IncorrectTokenCountException: DelimitedLineTokenizer 로 토큰화 할 때 컬럼 개수와 실제 토큰화 한 컬럼 수와 다를 때 발생하는 예외
- IncorrectLineLengthException: FixedLengthLineTokenizer 으로 토큰화 할 때 라인 전체 길이와 컬럼 길이의 총합과 일치하지 않을 때 발생
- `tokenizer.setStrict(false)`
  - LineTokenizer 의 Strict 속성을 false 로 설정하게 되면 Tokenizer 가 라인 길이를 검증하지 않는다.
  - Tokenizer 가 라인 길이나 컬럼명을 검증하지 않을 경우 예외가 발생하지 않는다.
  - FieldSet 은 성공적으로 리턴이 되며 두번째 범위 값은 빈 토큰을 가지게 된다.

### Json - JsonItemReader
- Json 데이터의 Parsing 과 Binding 을 JsonObjectReader 인터페이스 구현체에 위임하여 처리하는 ItemReader
- 두 가지 JsonObjectReader 구현체 제공: JacksonJsonObjectReader, GsonJsonObjectReader

```java
@Bean
public ItemReader itemReader() {
    return new JsonItemReaderBuilder<Customer>()
            .name("jsonReader")
            .resource(new ClassPathResource("customer.csv"))
            .jsonObjectReader(new JacksonJsonObjectReader<>(Customer.class))
            .build();
}
```

### DB - Cursor & Paging 이해
- 배치 어플리케이션은 실시간적 처리가 어려운 대용량 데이터를 다루며 이 때 DB I/O 의 성능문제와 메모리 자원의 효율성 문제를 해결할 수 있어야 한다.
- 스프링 배치에서는 대용량 데이터 처리를 위한 두 가지 해결방안을 제시하고 있다.
- Cursor Based 처리
  - 현재 행에 커서를 유지하며 다음 데이터를 호출하면 다음 행으로 커서를 이동하며 데이터 반환이 이루어지는 Streaming 방식의 I/O 이다.
  - ResultSet이 open 될 때마다 next() 메소드가 호출 되어 Database의 데이터가 반환되고 객체와 매핑이 이루어진다.
  - DB Connection 이 연결되면 배치 처리가 완료될 때 까지 데이터를 읽어오기 때문에 DB와 SocketTimeout을 충분히 큰 값으로 설정 필요
  - 모든 결과를 메모리에 할당하기 때문에 메모리 사용량이 많아지는 단점이 있다.
- Paging Based 처리
  - 페이징 단위로 데이터를 조회하는 방식으로 Page Size 만큼 한번에 메모리로 가지고 온 다음 한 개씩 읽는다.
  - 한 페이지를 읽을때마다 Connection을 맺고 끊기 때문에 대량의 데이터를 처리하더라도 SocketTimeout 예외가 거의 일어나지 않는다.
  - 시작 행 번호를 지정하고 페이지에 반환시키고자 하는 행의 수를 지정한 후 사용 – Offset, Limit
  - 페이징 단위의 결과만 메모리에 할당하기 때문에 메모리 사용량이 적어지는 장점이 있다.

{% include gallery id="Batch_19" %}

### DB - JdbcCursorItemReader
- Cursor 기반의 JDBC 구현체로서 ResultSet 과 함께 사용되며 Datasource 에서 Connection 을 얻어와서 SQL 을 실행한다.
- Thread 안정성을 보장하지 않기 때문에 멀티 스레드 환경에서 사용할 경우 동시성 이슈가 발생하지 않도록 별도 동기화 처리가 필요하다.

```java
public JdbcCursorItemReader itemReader() {
    return new JdbcCursorItemReaderBuilder<T>()
            .name("cursorItemReader")
            .fetchSize(int chunkSize) // Cursor 방식으로 데이터를 가지고 올 때 한번에 메모리에 할당할 크기를 설정한다
            .dataSource(DataSource) // DB 에 접근하기 위해 Datasource 설정
            .rowMapper(RowMapper) // 쿼리 결과로 반환되는 데이터와 객체를 매핑하기 위한 RowMapper 설정
            .beanRowMapper(Class<T>) // 별도의 RowMapper 을 설정하지 않고 클래스 타입을 설정하면 자동으로 객체와 매핑
            .sql(String sql) // ItemReader 가 조회 할 때 사용할 쿼리 문장 설정
            .queryArguments(Object... args) // 쿼리 파라미터 설정
            .maxItemCount(int count) // 조회 할 최대 item 수
            .currentItemCount(int count) // 조회 Item의 시작 지점
            .maxRows(int maxRows) // ResultSet 오브젝트가 포함 할 수 있는 최대 행 수
            .build();
}
```
{% include gallery id="Batch_20" %}

### DB - JpaCursorItemReader
- Cursor 기반의 JPA 구현체로서 EntityManagerFactory 객체가 필요하며 쿼리는 JPQL 을 사용한다.

```java
public JpaCursorItemReader itemReader() {
    return new JpaCursorItemReaderBuilder<T>()
            .name("cursorItemReader")
            .queryString(String JPQL) // ItemReader 가 조회 할 때 사용할 JPQL 문장 설정
            .EntityManagerFactory(EntityManagerFactory) // JPQL 을 실행하는 EntityManager 를 생성하는 팩토리
            .parameterValue(Map<String, Object> parameters) // 쿼리 파라미터 설정
            .maxItemCount(int count) // 조회 할 최대 item 수 
            .currentItemCount(int count) // 조회 Item의 시작 지점
            .build();
}
```

{% include gallery id="Batch_21" %}

### DB - JdbcPagingItemReader
- Paging 기반의 JDBC 구현체로서 쿼리에 시작 행 번호 (offset) 와 페이지에서 반환 할 행 수 (limit)를 지정해서 SQL 을 실행한다.
- 스프링 배치에서 offset과 limit을 PageSize에 맞게 자동으로 생성해 주며 페이징 단위로 데이터를 조회할 때 마다 새로운 쿼리가 실행한다.
- 멀티 스레드 환경에서 Thread 안정성을 보장하기 때문에 별도의 동기화를 할 필요가 없다.
- PagingQueryProvider
  - 쿼리 실행에 필요한 쿼리문을 ItemReader 에게 제공하는 클래스
  - 데이터베이스마다 페이징 전략이 다르기 때문에 각 데이터 베이스 유형마다 다른 PagingQueryProvider 를 사용한다.
  - Select 절, from 절, sortKey 는 필수로 설정해야 하며 where, group by 절은 필수가 아니다.

```java
public JdbcPagingItemReader itemReader() {
    return new JdbcPagingItemReaderBuilder<T>()
            .name("pagingItemReader")
            .pageSize(int pageSize)
            .dataSource(DataSource)
            .queryProvider(PagingQueryProvider) // DB 페이징 전략에 따른 PagingQueryProvider 설정
            .rowMapper(Class<T>)
            .selectClause(String selectClause)
            .fromClause(String fromClause)
            .whereClause(String whereClause)
            .groupClause(String groupClause)
            .sortKeys(Map<String, Order> sortKeys)
            .parameterValues(Map<String, Object> parameters)
            .maxItemCount(int count)
            .currentItemCount(int count)
            .maxRows(int maxRows)
            .build();
}
```

### DB - JpaPagingItemReader
- Paging 기반의 JPA 구현체로서 EntityManagerFactory 객체가 필요하며 쿼리는 JPQL 을 사용한다. 동기화 문제에 안전하다.

```java
private ItemReader<? extends Customer> customerItemReader() {
    return new JpaPagingItemReaderBuilder<Customer>()
            .name("itemReader")
            .entityManagerFactory(entityManagerFactory)
            .pageSize(10)
            .queryString("select c from Customer c join fetch c.address")
            .build();
}
```

### ItemReaderAdapter
- 배치 Job 안에서 이미 있는 DAO 나 다른 서비스를 ItemReader 안에서 사용하고자 할 때 위임 역할을 한다.
- targetObject의 targetMethod 에서 반환하는 객체를 Chunk에 저장한다.

## 스프링 배치 청크 프로세스 활용 - ItemWriter
- Resource 와 LineAggregator 두 가지가 요소가 필요하다.
- LineAggregator
  - Item 을 받아서 String 으로 변환하여 리턴한다.
  - FieldExtractor를 사용해서 처리할 수 있다.
  - 구현체: PassThroughLineAggregator, DelimitedLineAggregator, FormatterLineAggregator
- FieldExtractor
  - 전달 받은 Item 객체의 필드를 배열로 만들어서 제공하는 인터페이스
  - 구현체: BeanWrapperFieldExtractor, PassThroughFieldExtractor

```java
public FlatFileItemReader itemReader() {
    return new FlatFileItemWriterBuilder<T>()
            .name(String name)
            .resource(Resource)
            .lineAggregator(LineAggregator<T>) // 객체를 String 으로 변환하는 LineAggregator 객체 설정
            .append(boolean) // 존재하는 파일에 내용을 추가할 것인지 여부 설정
            .fieldExtractor(FieldExtractor<T>) // 객체 필드를 추출해서 배열로 만드는 FieldExtrator 설정
            .headerCallback(FlatFileHeaderCallback)
            .footerCallback(FlatFileFooterCallback)
            .shouldDeleteIfExists(boolean) // 파일이 이미 존재한다면 삭제
            .shouldDeleteIfEmpty(boolean) // 파일의 내용이 비어 있다면 삭제
            .delimited().delimiter(String delimiter) // 파일의 구분자를 기준으로 파일을 작성하도록 설정
            .formatted().format(String format) // 파일의 고정길이를 기준으로 파일을 작성하도록 설정
            .build();
}
```

### JsonFileItemWriter
```java
public JsonFileItemWriterBuilder itemReader() {
    return JsonFileItemWriterBuilder <T>()
            .name(String name)
            .resource(Resource)
            .append(boolean)
            .jsonObjectMarshaller(JsonObjectMarshaller) // JsonObjectMarshaller 객체 설정
            .headerCallback(FlatFileHeaderCallback)
            .footerCallback(FlatFileFooterCallback)
            .shouldDeleteIfExists(boolean)
            .shouldDeleteIfEmpty(boolean)
            .build();
}
```

### DB - JdbcBatchItemWriter
- JdbcCursorItemReader 설정과 마찬가지로 datasource 를 지정하고, sql 속성에 실행할 쿼리를 설정
- JDBC의 Batch 기능을 사용하여 bulk insert/update/delete 방식으로 처리(성능에 이점)

{% include gallery id="Batch_22" %}

```java
public JdbcBatchItemWriter itemWriter() {
    return new JdbcBatchItemWriterBuilder<T>()
            .name(String name)
            .datasource(Datasource)
            .sql(String sql)
            .assertUpdates(boolean) // 트랜잭션 이후 적어도 하나의 항목이 행을 업데이트 혹은 삭제하지 않을 경우 예외발생여부를 설정함, 기본값은 true
            .beanMapped() // Pojo 기반으로 Insert SQL의 Values를 매핑
            .columnMapped() // Key,Value 기반으로 Insert SQL의 Values를 매핑
            .build();
}
```

### DB - JpaItemWriter
- JPA Entity 기반으로 데이터를 처리하며 EntityManagerFactory 를 주입받아 사용한다.
- Entity를 하나씩 chunk 크기 만큼 insert 혹은 merge 한 다음 flush 한다.
- ItemReader 나 ItemProcessor 로 부터 아이템을 전발 받을 때는 Entity 클래스 타입으로 받아야 한다.

```java
public JpaItemWriter itemWriter() {
    return new JpaItemWriterBuilder<T>()
            .usePersist(boolean) // Entity 를 persist() 할 것인지 여부 설정, false 이면 merge() 처리
            .entityManagerFactory(EntityManagerFactory)
            .build();
}
```

## 스프링 배치 청크 프로세스 활용 - ItemProcessor
### CompositeItemProcessor
- ItemProcessor 들을 연결(Chaining)해서 위임하면 각 ItemProcessor 를 실행시킨다.
- 이전 ItemProcessor 반환 값은 다음 ItemProcessor 값 으로 연결된다.

```java
private ItemProcessor<? super String, String> customItemProcessor() {
    List list = new ArrayList<>();
    list.add(new CustomItemProcessor());
    list.add(new CustomItemProcessor2());

    return new CompositeItemProcessorBuilder<>()
            .delegates(list)
            .build();
}
```

## 목차 소개
### Repeat
- 특정 조건이 충족 될 때까지 (또는 특정 조건이 아직 충족되지 않을 때까지) Job 또는 Step 을 반복하도록 배치 애플리케이션을 구성 할 수 있다.
- 스프링 배치에서는 Step 의 반복과 Chunk 반복을 RepeatOperation 을 사용해서 처리하고 있다.
- 기본 구현체로 RepeatTemplate 를 제공한다.
- 반복을 종료할 것인지 여부를 결정하는 세가지 항목
  - RepeatStatus: 스프링 배치의 처리가 끝났는지 판별하기 위한 열거형(enum), CONTINUABLE / FINISHED
  - CompletionPolicy: RepeatTemplate 의 iterate 메소드 안에서 반복을 중단할지 결정, 정상 종료를 알리는데 사용된다. (여러가지 기본 구현제 제공))
  - ExceptionHandler: RepeatCallback 안에서 예외가 발생하면 RepeatTemplate 가 ExceptionHandler 를 참조해서 예외를 다시 던질지 여부 결정, 예외를 받아서 다시 던지게 되면 반복 종료, 비정상 종료를 알리는데 사용된다. (여러가지 기본 구현체 제공)

{% include gallery id="Batch_23" %}

### FaultTolerant
- 스프링 배치는 Job 실행 중에 오류가 발생할 경우 장애를 처리하기 위한 기능을 제공하며 이를 통해 복원력을 향상시킬 수 있다.
- 오류가 발생해도 Step 이 즉시 종료되지 않고 Retry 혹은 Skip 기능을 활성화 함으로써 내결함성 서비스가 가능하도록 한다.
  - Skip: ItemReader / ItemProcessor / ItemWriter 에 적용 할 수 있다.
  - Retry: ItemProcessor / ItemWriter 에 적용할 수 있다.
- FaultTolerant 구조는 청크 기반의 프로세스 기반위에 Skip 과 Retry 기능이 추가되어 재정의 되어 있다.

{% include gallery id="Batch_24" %}
```java
public Step batchStep() {
    return new stepBuilderFactory.get("batchStep")
            .<I, O>chunk(10)
            .reader(ItemReader)
            .writer(ItemWriter)
            .falutTolerant()
            .skip(Class<? extends Throwable> type) 
            .skipLimit(int skipLimit)
            .skipPolicy(SkipPolicy skipPolicy) 
            .noSkip(Class<? extends Throwable> type) 
            .retry(Class<? extends Throwable> type) 
            .retryLimit(int retryLimit)
            .retryPolicy(RetryPolicy retryPolicy) 
            .backOffPolicy(BackOffPolicy backOffPolicy) // 다시 Retry 하기 까지의 지연시간 (단위:ms)을 설정
            .noRetry(Class<? extends Throwable> type) 
            .noRollback(Class<? extends Throwable> type) // 예외 발생 시 Rollback 하지 않을 예외 타입 설정
            .build();
}
```

### Skip
- Skip은 데이터를 처리하는 동안 설정된 Exception이 발생했을 경우, 해당 데이터 처리를 건너뛰는 기능이다.
- ItemReader 는 예외가 발생하면 해당 아이템만 스킵하고 계속 진행한다.
- ItemProcessor 와 ItemWriter 는 예외가 발생하면 스킵된 아이템을 제외한 나머지 아이템들을 가지고 다시 처리하게 된다.
- Skip 기능은 내부적으로 SkipPolicy 를 통해서 구현되어 있다. 스프링 배치가 기본적으로 제공하는 SkipPolicy 구현체들이 있으며 필요 시 직접 생성해서 사용할 수 있다. 그리고 내부적으로 Classfier 클래스들을 활용하고 있다.
  - AlwaysSkipItemSkipPolicy: 항상 skip 한다.
  - ExceptionClassifierSkipPolicy: 예외대상을 분류하여 skip 여부를 결정한다.
  - CompositeSkipPolicy: 여러 SkipPolicy 를 탐색하면서 skip 여부를 결정한다.
  - LimitCheckingItemSkipPolicy: Skip 카운터 및 예외 등록 결과에 따라 skip 여부를 결정한다.(기본값)
  - NeverSkipItemSkipPolicy: skip 을 하지 않는다.
- Skip 가능 여부를 판별하는 기준은 다음과 같다.
  - 스킵 대상에 포함된 예외인지 여부
  - 스킵 카운터를 초과 했는지 여부

### Retry
- Retry는 ItemProcess, ItemWriter 에서 설정된 Exception이 발생했을 경우, 지정한 정책에 따라 데이터 처리를 재시도하는 기능이다.
- 오류 발생 시 재시도 설정에 의해서 Chunk 단계의 처음부터 다시 시작한다. 아이템은 ItemReader에서 캐시로 저장한 값을 사용한다.
- Retry가 가능한 경우 RetryCallback을 호출하고 Retry를 모두 소진한 경우 RecoveryCallback을 호출하여 Skip 여부 등을 결정한다.
- Skip시에는 Chunk의 처음이 아닌 ItemProcessor의 처음으로 돌아가서 해당 item을 제거한 list로 다시 작업을 진행한다.
- Retry 기능은 내부적으로 RetryPolicy 를 통해서 구현되어 있다. 또한 Item 별로 Retry 횟수를 카운트한다.
- Retry 가능 여부를 판별하는 기준
  - 재시도 대상에 포함된 예외인지 여부
  - 재시도 카운터를 초과 했는지 여부
- RetryPolicy
  - 기본적으로 제공하는 RetryPolicy 구현체들이 있으며 필요 시 직접 생성해서 사용할 수 있다.
  - SimpleRetryPolicy: 재시도 횟수 및 예외 등록 결과에 따라 재시도 여부를 결정한다. 기본값으로 설정된다.
  
{% include gallery id="Batch_25" %}

### Skip & Retry Architecture
{% include gallery id="Batch_26" layout = "half"%}

## 스프링 배치 멀티 스레드 프로세싱
### 기본 개념
- TaskExecutorRepeatTemplate의 TaskExecutor가 ThreadPoll 에서 쓰레드를 통해 ExecutingRunnable 의 `run()` 메소드를 실행시킨다. 해당 메소드 안에서 ChunkOrientedTasklet이 실행된다. 
- 스프링 배치는 기본적으로 단일 스레드 방식으로 작업을 처리한다.
- 성능 향상과 대규모 데이터 작업를 위한 비동기 처리 및 Scale out 기능을 제공한다.
- AsyncItemProcessor / AsyncItemWriter: ItemProcessor 에게 별도의 스레드가 할당되어 작업을 처리하는 방식
- Multi-threaded Step: Step 내 Chunk 구조인 ItemReader, ItemProcessor, ItemWriter 마다 여러 스레드가 할당되어 실행 하는 방법
- Parallel Steps: Step 마다 스레드가 할당되어 여러개의 Step을 병렬로 실행하는 방법
- Partitioning: Master/Slave 방식으로서 Master 가 데이터를 파티셔닝 한 다음 각 파티션에게(각 Step) 스레드를 할당하여 Slave 가 독립적으로 작동하는 방식

### AsyncItemProcessor / AsyncItemWriter
- Step 안에서 ItemProcessor 가 비동기적으로 동작하는 구조
- AsyncItemProcessor 와 AsyncItemWriter 가 함께 구성이 되어야 함.
- AsyncItemProcessor 로부터 AsyncItemWriter 가 받는 최종 결과값은 `List<Future<T>>` 타입이며 비동기 실행이 완료될 때까지 대기한다.
- spring-batch-integration 의존성이 필요하다.

```yaml
implementation 'org.springframework.batch:spring-batch-integration'
```
- AsyncItemWriter 는 비동기 실행 결과 값들을 모두 받아오기 까지 대기해야 한다.

```java
for (Future<T> future : items) { 
  list.add(future.get());
}
```
- AsyncItemProcessor: 내부적으로 실제 ItemProcessor 에게 실행을 위임하고 결과를 Future 에 저장한다.
- AsyncItemWriter: 내부적으로 실제 ItemWriter 에게 최종 결과값을 넘겨주고 실행을 위임한다.

```java
@Nullable
public Future<O> process(final I item) throws Exception {
    final StepExecution stepExecution = getStepExecution();
    FutureTask<O> task = new FutureTask<>(new Callable<O>() {
        public O call() throws Exception {
            if (stepExecution != null) {
                StepSynchronizationManager.register(stepExecution);
            }
            try {
                return delegate.process(item);
            }
            finally {
                if (stepExecution != null) {
                    StepSynchronizationManager.close();
                }
            }
        }
    });
    taskExecutor.execute(task);
    return task;
}
```
### Multi-threaded Step
- Step 내에서 멀티 스레드로 Chunk 기반 처리가 이루어지는 구조
- TaskExecutorRepeatTemplate 이 반복자로 사용되며 설정한 개수 (throttleLimit) 만큼의 스레드를 생성하여 수행한다. 
- ItemReader 는 Thread-safe 인지 반드시 확인해야 한다. 데이터를 소스로 부터 읽어오는 역할이기 때문에 스레드마다 중복해서 데이터를 읽어오지 않도록 동기화가 보장되어야 한다.
- 스레드마다 새로운 Chunk 가 할당되어 데이터 동기화가 보장된다. 스레드끼리 Chunk 를 서로 공유하지 않는다.

{% include gallery id="Batch_29" %}

```java
@Bean
public Step step1() {
    return stepBuilderFactory.get("step1")
            .<Customer, Customer2>chunk(1000)
            .reader(itemReader())
            .processor(new ItemProcessor<Customer, Customer2>() {
                @Override
                public Customer2 process(Customer customer) throws Exception {
                    return new Customer2(customer);
                }
            })
            .writer(customItemWriter)
            .taskExecutor(taskExecutor())
            .build();
}

@Bean
public TaskExecutor taskExecutor() {
    ThreadPoolTaskExecutor threadPoolTaskExecutor = new ThreadPoolTaskExecutor();
    threadPoolTaskExecutor.setCorePoolSize(4);
    threadPoolTaskExecutor.setMaxPoolSize(8);
    threadPoolTaskExecutor.setThreadNamePrefix("async-thread");

    return threadPoolTaskExecutor;
}
```

### Parallel Steps
- SplitState 를 사용해서 여러 개의 Flow 들을 병렬적으로 실행하는 구조
- 실행이 다 완료된 후 FlowExecutionStatus 결과들을 취합해서 다음 단계 결정을 한다.

{% include gallery id="Batch_30" %}

```java
@Bean
public Job job() {
    return jobBuilderFactory.get("job")
            .start(flow1())
            .split(taskExecutor()).add(flow2())
            .end()
            .build();
}
```
- flow1 과 flow2 가 병렬처리된다.

### Partitioning
- MasterStep(PartitionStep) 이 SlaveStep 을 실행시키는 구조
- SlaveStep 은 각 스레드에 의해 독립적으로 실행이 됨
- SlaveStep은 독립적인 StepExecution 파라미터 환경을 구성함
- SlaveStep은 ItemReader / ItemProcessor / ItemWriter 등을 가지고 동작하며 작업을 독립적으로 병렬 처리한다.
- MasterStep 은 PartitionStep 이며 SlaveStep 은 TaskletStep, FlowStep 등이 올 수 있다.
- PartitionStep
  - 파티셔닝 기능을 수행하는 Step 구현체
  - 파티셔닝을 수행 후 StepExecutionAggregator 를 사용해서 StepExecution 의 정보를 최종 집계한다
- PartitionHandler
  - PartitionStep 에 의해 호출되며 스레드를 생성해서 WorkStep 을 병렬로 실행한다.
  - WorkStep 에서 사용할 StepExecution 생성은 StepExecutionSplitter 과 Partitioner에게 위임한다.
- StepExecutionSplitter
  - WorkStep 에서 사용할 StepExecution 을 gridSize 만큼 생성한다.
  - Partitioner 를 통해 ExecutionContext 를 얻어서 StepExecution 에 매핑한다.
- Partitioner
  - StepExecution 에 매핑 할 ExecutionContext 를 gridsize 만큼 생성한다.
  - 각 ExecutionContext 에 저장된 정보는 WorkStep 을 실행하는 스레드마다 독립적으로 참조 및 활용 가능하다.

{% include gallery id="Batch_31" %}
- 각 스레드는 자신에게 할당된 StepExecution 을 가지고 있다.
- 각 스레드는 자신에게 할당된 청크 클래스를 참조한다.
- Thread-safe 를 만족한다.
- `jobConfig`

```java
@Configuration
@RequiredArgsConstructor
public class JobConfiguration {

    private final JobBuilderFactory jobBuilderFactory;
    private final StepBuilderFactory stepBuilderFactory;
    private final DataSource dataSource;
    private final EntityManagerFactory entityManagerFactory;
    private final CustomItemWriter customItemWriter;
    private final CustomTasklet customTasklet;

    @Bean
    public Job job() {
        return jobBuilderFactory.get("job")
                .start(masterStep())
                .build();
    }

    @Bean
    public Step masterStep() {
        return stepBuilderFactory.get("masterStep")
                .partitioner("slaveStep", partitioner())
                .step(slaveStep())
                .gridSize(4)
                .taskExecutor(taskExecutor())
                .build();
    }

    @Bean
    public Step slaveStep() {
        return stepBuilderFactory.get("slaveStep")
                .<Customer, Customer2>chunk(100)
                .reader(itemReader(null, null))
                .processor(new ItemProcessor<Customer, Customer2>() {
                    @Override
                    public Customer2 process(Customer item) throws Exception {
                        return new Customer2(item);
                    }
                })
                .writer(customItemWriter)
                .build();
    }

    @Bean
    @StepScope
    public ItemStreamReader<? extends Customer> itemReader(
            @Value("#{stepExecutionContext['minValue']}") Long minValue,
            @Value("#{stepExecutionContext['maxValue']}") Long maxValue) {

        HashMap<String, Object> map = new HashMap<>();
        map.put("minValue", minValue);
        map.put("maxValue", maxValue);

        return new JpaPagingItemReaderBuilder<Customer>()
                .name("itemReader")
                .pageSize(100)
                .queryString("select c from Customer c where customer_id >= :minValue and customer_id <= :maxValue")
                .entityManagerFactory(entityManagerFactory)
                .parameterValues(map)
                .build();
    }

    @Bean
    public Partitioner partitioner() {
        ColumnRangePartitioner columnRangePartitioner = new ColumnRangePartitioner();
        columnRangePartitioner.setColumn("customer_id");
        columnRangePartitioner.setDataSource(dataSource);
        columnRangePartitioner.setTable("Customer");

        return columnRangePartitioner;
    }

    @Bean
    public TaskExecutor taskExecutor() {
        ThreadPoolTaskExecutor threadPoolTaskExecutor = new ThreadPoolTaskExecutor();
        threadPoolTaskExecutor.setCorePoolSize(4);
        threadPoolTaskExecutor.setMaxPoolSize(8);
        threadPoolTaskExecutor.setThreadNamePrefix("async-thread");

        return threadPoolTaskExecutor;
    }
}
```
- `ColumnRangePartitioner`

```java
public class ColumnRangePartitioner implements Partitioner {

    private JdbcOperations jdbcTemplate;

    private String table;

    private String column;

    public void setTable(String table) {
        this.table = table;
    }

    public void setColumn(String column) {
        this.column = column;
    }

    public void setDataSource(DataSource dataSource) {
        jdbcTemplate = new JdbcTemplate(dataSource);
    }

    @Override
    public Map<String, ExecutionContext> partition(int gridSize) {
        int min = jdbcTemplate.queryForObject("SELECT MIN(" + column + ") from " + table, Integer.class);
        int max = jdbcTemplate.queryForObject("SELECT MAX(" + column + ") from " + table, Integer.class);
        int targetSize = (max - min) / gridSize + 1;

        Map<String, ExecutionContext> result = new HashMap<String, ExecutionContext>();
        int number = 0;
        int start = min;
        int end = start + targetSize - 1;

        while (start <= max) {
            ExecutionContext value = new ExecutionContext();
            result.put("partition" + number, value);

            if (end >= max) {
                end = max;
            }
            value.putInt("minValue", start);
            value.putInt("maxValue", end);
            start += targetSize;
            end += targetSize;
            number++;
        }

        return result;
    }
}
```

### SynchronizedItemStreamReader
- Thread-safe 하지 않은 ItemReader 를 Thread-safe 하게 처리하도록 하는 역할을 한다.
- DB에서 동일한 item을 읽어와서 중복 저장되는 것을 방지한다.

## 스프링 배치 이벤트 리스너
### 기본개념
- Listener 는 배치 흐름 중에 Job, Step, Chunk 단계의 실행 전후에 발생하는 이벤트를 받아 용도에 맞게 활용할 수 있도록 제공하는 인터셉터 개념의 클래스
- 각 단계별로 로그기록을 남기거나 소요된 시간을 계산하거나 실행상태 정보들을 참조 및 조회 할 수 있다.
- 이벤트를 받기 위해서는 Listener 를 등록해야 하며 등록은 API 설정에서 각 단계별로 지정 할 수 있다.
- Job
  - JobExecutionListener – Job 실행 전후
- Step
  - StepExecutionListener – Step 실행 전후
  - ChunkListener – Chunk 실행 전후 (Tasklet 실행 전후) , 오류 시점
  - ItemReadListener – ItemReader 실행 전후, 오류 시점, item 이 null 일 경우 호출 안됨
  - ItemProcessListener – ItemProcessor 실행 전후, 오류 시점, item 이 null 일 경우 호출 안됨
  - ItemWriteListener – ItemWriter 실행 전후, 오류 시점, item 이 null 일 경우 호출 안됨
- SkipListener – 읽기, 쓰기, 처리 Skip 실행 시점, Item 처리가 Skip 될 경우 Skip 된 item을 추적함
- RetryListener – Retry 시작, 종료, 에러 시점
- 구현 방식: 어노테이션 방식, 인터페이스 방식

{% include gallery id="Batch_32" %}

### JobExecutionListener / StepExecutionListener
- Job 의 성공여부와 상관없이 호출된다.
- Step 의 성공여부와 상관없이 호출된다.

```java
@Bean
public Job job() {
    return jobBuilderFactory.get("job")
            .start(step())
            .listener(JobExecutionListener)
            .listener(Object) // 어노테이션방식
            .build();
}
```
### ChunkListener / ItemReadListener /ItemProcessListener /ItemWriteListener
- ChunkListener
  - `void beforeChunk(ChunkContext context)`: 트랜잭션이 시작되기 전 호출, ItemReader 의 read() 메소드를 호출하기 전이다.
  - `void afterChunk(ChunkContext context)`: Chunk 가 커밋된 후 호출, ItemWriter 의 write() 메소드를 호출한 후이다.  롤백 되었다면 호출되지 않는다.
  - `void afterChunkError(ChunkContext context)`:  오류 발생 및 롤백이 되면 호출
- ItemReadListener
  - `void beforeRead()`: read() 메소드를 호출하기 전 매번 호출
  - `void afterRead(T item)`: read() 메소드를 호출이 성공할 때 마다 호출
  - `void onReadError(Exception ex)`: 읽는 도중 오류가 발생하면 호출
- ItemProcessListener
  - `void beforeProcess(T item)`: process() 메소드를 호출하기 전 매번 호출
  - `void afterWrite(List<? extends S> items)`:  process() 메소드 호출이 성공할 때 매번 호출
  - `void onWriteError(Exception exception, List<? extends S> items)`: 처리 도중 오류가 발생하면 호출
- ItemWriteListener
  - `void beforeWrite(List<? extends S> items)`: write() 메소드를 호출하기 전 호출
  - `void afterWrite(List<? extends S> items)`: write() 메소드 호출이 성공할 때 호출
  - `void onWriteError(Exception exception, List<? extends S> items)`: 쓰기 도중 오류가 발생하면 호출

### SkipListener & RetryListener
#### SkipListener
- `void onSkipInRead(Throwable t)`: read 수행중 Skip 이 발생할 경우 호출
- `void onSkipInWrite(S item, Throwable t)`: write 수행중 Skip 이 발생할 경우 호출
- `void onSkipInProcess(T item, Throwable t)`: process 수행중 Skip 이 발생할 경우 호출

#### RetryListener
- `boolean open(RetryContext context, RetryCallback<T, E> callback)`: 재 시도 전 매번 호출, false 를 반환할 경우 retry 를 시도하지 않음
- `void close(RetryContext context, RetryCallback<T, E> callback, Throwable throwable)`: 재 시도 후 매번 호출
- `void onError(RetryContext context, RetryCallback<T, E> callback, Throwable throwable)`: 예외 발생시 호출

{% include gallery id="Batch_33" %}

## JobExplorer / JobRegistry / JobOperator
API 요청 등에 맞춰서 원하는 Job을 실행시키기거나 중단시킬 수 있는 운영적인 측면에서의 활용이다.
### JobExplorer
- JobRepository 의 readonly 버전
- 실행 중인 Job 의 실행 정보인 JobExecution 또는 Step의 실행 정보인 StepExecution 을 조회할 수 있다.

### JobRegistry
- 생성된 Job 을 자동으로 등록, 추적 및 관리하며 여러 곳에서 job 을 생성한 경우 ApplicationContext 에서 job을 수집해서 사용할 수 있다.
- 기본 구현체로 map 기반의 MapJobRegistry 클래스를 제공한다. jobName 을 Key로 하고 job 을 값으로 하여 매핑한다.
- Job등록: JobRegistryBeanPostProcessor – BeanPostProcessor 단계에서 bean 초기화 시 자동으로 JobRegistry에 Job을 등록 시켜준다.

### JobOperator
- JobExplorer, JobRepository, JobRegistry, JobLauncher 를 포함하고 있으며 배치의 시작, 중단, 재시작, job 요약 등의 모니터링이 가능하다.
- 기본 구현체로 SimpleJobOprerator 클래스를 제공한다.

[1]: https://www.inflearn.com/course/스프링-배치/dashboard